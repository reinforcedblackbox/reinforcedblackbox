---
layout: post
title: Far reaching
description: Where does NS come in 
image: assets/images/pic05.jpg
---

In this context, the development of artificial neural networks is a reflection of the universal principles that govern adaptation and survival. These networks, inspired by the biological counterparts, serve as powerful tools for approximating functions and making sense of complex data. In spite of its inherent simplicity, It doesn't matter how random or chaotic the data may seem; neural networks possess the remarkable ability to fit this data and extract meaningful patterns. This adaptability is a testament to their effectiveness in dealing with the complexities of the world.

We should strive to build anti ad hoc solutions. We have this inherent sense of going through this world interacting with it and building a rich model of it in a short time span, storing what's important to a long term storage, recalling that to that shorted information, to interacting with it in the short term, and the cycle continues. Where even the most state of the art AI currently in research is just at best a very good statistical generalization on input data mapped to some output based on conditional probability. Current AI is very lacking in information binding, continual learning, and contextual understanding.
Information binding is the ability to integrate information from different sources and form a coherent understanding of the world. Current AI systems are not able to do this well, and often rely on hand-crafted rules or heuristics to combine information.
Continual learning is the ability to learn new information and adapt to changes in the environment. Current AI systems are not able to do this well, and often require to be retrained from scratch when new information is presented to them.
Contextual understanding is the ability to understand the meaning of information in context. Direct effect of this is Adversarial attacks on neural networks can be seen in applications like image recognition and autonomous vehicles, weird perturbations of input can cause the network to completely fail.   Current AI systems often misunderstand the meaning of information when it is presented in a different context.
Absence of short-term memory network. Biological neural networks do not learn and generalize on every piece of information stimulus comes in. Coming up with specific solutions like an attention mechanism doesn't count. We need to follow biology more closely and come up with specific networks that can continuously observe incoming information and then generalize based on the observed information over time, based on the rewards that that particular information can potentially give you in the future. Using recurrent

